{"cells":[{"cell_type":"markdown","metadata":{"id":"tbTYFRhJoaBu"},"source":["# MNIST digit classification before and after shuffling\n","\n","**Task:**\n","In this notebook you will use a convolutional neural network (CNN), to train two neural networks on the original and the pixel shuffled MNIST dataset and compare the performances. Before you used already the Fully Connected NN with the same data\n","\n","\n","**Dataset:** You work with the MNIST dataset. We have 60'000 28x28 pixel greyscale images of digits and want to classify them into the right label (0-9). In the second part the original pixel in the image are shuffled.\n","\n","**Content:**\n","* load the original MNIST data and create a randomly pixel shuffled version of the data\n","* visualize samples of the orginal and shuffled version of the data\n","* use keras to train a CNN with the original and shuffled data and compare the perfomance on new unseen test data\n","* check if the local structure of the pixels within the images have an impact on the classification performance when you use a CNN\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PEIS4WvpsT5t"},"source":["#### Imports\n","\n","In the next two cells, we load all the required libraries and download the MNIST data, normalize the pixelvalues to be between 0 and 1, and seperate it into a training and validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6S_hQX5oaBw","scrolled":true},"outputs":[],"source":["# load required libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.style.use('default')\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","import os\n","os.environ[\"KERAS_BACKEND\"] = \"torch\"\n","import keras\n","import torch # not needed yet\n","\n","print(f'Keras_version: {keras.__version__}')# 3.5.0\n","print(f'torch_version: {torch.__version__}')# 2.5.1+cu121\n","print(f'keras backend: {keras.backend.backend()}')\n","\n","# Keras Building blocks\n","from keras.models import Sequential\n","from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation\n","from keras.optimizers import SGD\n","from keras.utils import to_categorical\n","from keras import optimizers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sZ8lqFfoaB2"},"outputs":[],"source":["from keras.datasets import mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# separate x_train in X_train and X_val, same for y_train\n","X_train=x_train[0:50000] / 255 #divide by 255 so that they are in range 0 to 1\n","Y_train=to_categorical(y_train[0:50000],10) # one-hot encoding\n","\n","X_val=x_train[50000:60000] / 255\n","Y_val=to_categorical(y_train[50000:60000],10)\n","\n","X_test=x_test / 255\n","Y_test=to_categorical(y_test,10)\n","\n","del x_train, y_train, x_test, y_test\n","\n","X_train=np.reshape(X_train, (X_train.shape[0],28,28,1))\n","X_val=np.reshape(X_val, (X_val.shape[0],28,28,1))\n","X_test=np.reshape(X_test, (X_test.shape[0],28,28,1))\n","\n","print(X_train.shape)\n","print(X_val.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"3ly7CrHtLUP9"},"source":["Let's visualize the first 4 MNIST images before shuffling the pixels randomly. It is very easy to recognise the true label of the digits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4gUgwGUeftF"},"outputs":[],"source":["# visualize the 4 first mnist images before shuffling the pixels\n","plt.figure(figsize=(12,12))\n","for i in range(0,4):\n","    plt.subplot(1,4,(i+1))\n","    plt.imshow((X_train[i,:,:,0]),cmap=\"gray\")\n","    plt.title('true label: ' + str(np.argmax(Y_train,axis=1)[i]))\n","    #plt.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"m6laMbqWLqlz"},"source":["In the next cell we shuffle the pixel of each image randomly. Note that we shuffle every image in same manner!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o744FOiN1S6y"},"outputs":[],"source":["# function to shuffle the pixel order within an image\n","# used to shuffel the pixels of all mnist images in the same manner\n","def shuffel_pixels(idx, data):\n","    data_new=np.zeros((data.shape))\n","    for i,img in enumerate(data):\n","        data_new[i] = img.flatten()[idx].reshape((28,28,1))\n","    return data_new\n","\n","np.random.seed(42)\n","shuffel_idx = np.random.permutation(np.arange(28*28))\n","X_train_shuffle = shuffel_pixels(shuffel_idx, X_train)\n","X_val_shuffle = shuffel_pixels(shuffel_idx, X_val)\n","X_test_shuffle = shuffel_pixels(shuffel_idx, X_test)"]},{"cell_type":"markdown","metadata":{"id":"VXK_HJbdMAeg"},"source":["Let's visualize the first 4 MNIST images after shuffling the pixels randomly around. Now as a human you have no chance to recognise the true label of the digits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrZk47bkoaB7"},"outputs":[],"source":["# visualize the 4 first mnist images after shuffling the pixels\n","plt.figure(figsize=(12,12))\n","for i in range(0,4):\n","    plt.subplot(1,4,(i+1))\n","    plt.imshow((X_train_shuffle[i,:,:,0]), cmap=\"gray\")\n","    plt.title('true label: ' + str(np.argmax(Y_train,axis=1)[i]))"]},{"cell_type":"markdown","metadata":{"id":"ZaRFUEP8HJkq"},"source":["# CNN as classification model for MNIST data\n","\n","Now, we train a CNN to classify the MNIST data. We use the same netwok architecture to train first with the original data and then with the shuffled data.\n","* Use a CNN with 2 convolution blocks and 2 fully connected layers as classification model\n","* train it once on the original train data and check the performance on the original test data\n","* train it once on the shuffeled train data and check the performance on the accordingly shuffled test data"]},{"cell_type":"markdown","metadata":{"id":"cFJtO1FFHJkz"},"source":["### Train the CNN on the **original data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iq45_Gs1HJk1"},"outputs":[],"source":["# check the shape of the orginal data\n","# we need matrices as input\n","X_train.shape,Y_train.shape,X_val.shape,Y_val.shape"]},{"cell_type":"markdown","metadata":{"id":"fFBbAdLeTZuv"},"source":["In the next cell we define the hyperparameters and architecture of the CNN. We use:\n","- the relu activation function  \n","- batchsize of 128  \n","- kernelsize of 3x3  \n","- poolingsize of 2x2   \n","- our inputs are the greyscaled MNIST images, so the shape is 28x28x1  \n","- we use 2 convolutional blocks with 8 filters and then a maxpooling layer followed by again 2 convolutional blocks with 16 filters and then a maxpooling  \n","- we flatten the output and use a fully connected layer with 40 nodes and the output has 10 nodes with the softmax activation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSfYQ4f1KYVp"},"outputs":[],"source":["# here we define the hyperparameter of the CNN\n","batch_size = 128\n","nb_classes = 10\n","img_rows, img_cols = 28, 28\n","kernel_size = (3, 3)\n","input_shape = (img_rows, img_cols, 1)\n","pool_size = (2, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xwh0iYrHJk_"},"outputs":[],"source":["# define CNN with 2 convolution blocks and 2 fully connected layers\n","model = Sequential()\n","\n","model.add(Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\n","model.add(Activation('relu'))\n","model.add(Convolution2D(8, kernel_size,padding='same'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=pool_size))\n","\n","##### Your code here ######\n","##### add two convolutional layers with each 16 filter and a maxpooling layer\n","\n","model.add(Convolution2D(16, kernel_size,padding='same'))\n","model.add(Activation('relu'))\n","model.add(Convolution2D(16,kernel_size,padding='same'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=pool_size))\n","\n","##### End of your code  ######\n","\n","model.add(Flatten())\n","model.add(Dense(40))\n","model.add(Activation('relu'))\n","model.add(Dense(nb_classes))\n","model.add(Activation('softmax'))\n","\n","# save the model for the shuffled data\n","model2 = clone_model(model)\n","\n","# compile model and intitialize weights\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blxHZguwHJlG"},"outputs":[],"source":["# summarize model along with number of model weights\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"430DSTDIHJlP"},"outputs":[],"source":["# train the model\n","history=model.fit(X_train, Y_train,\n","                  batch_size=128,\n","                  epochs=10,\n","                  verbose=1,\n","                  validation_data=(X_val, Y_val)\n","                 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8GcmSWoHJlX"},"outputs":[],"source":["# plot the development of the accuracy and loss during training\n","plt.figure(figsize=(12,4))\n","plt.subplot(1,2,(1))\n","plt.plot(history.history['accuracy'],linestyle='-.')\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='lower right')\n","plt.subplot(1,2,(2))\n","plt.plot(history.history['loss'],linestyle='-.')\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='upper right')"]},{"cell_type":"markdown","metadata":{"id":"CAcwJRvDHJlf"},"source":["#### Prediction on the test set after training on original data\n","\n","Now, let us use CNN that was trained on the original data to predict new unseen data (our testdata). We determine the confusion matrix and the accuracy on the testdata to evaluate the classification performance."]},{"cell_type":"code","source":["#### Exercise\n","#### Use the trained model to calculate the accuracy and the confusion matrix on the test data\n","\n","### Your code here ###\n","\n","# predict each instance of the testset\n","pred=model.predict(X_test)\n","# get confusion matrix\n","cm = confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(pred, axis=1))\n","\n","acc_fc = np.sum(np.argmax(Y_test,axis=1)==np.argmax(pred,axis=1))/len(pred)\n","print(\"Accuracy = \" , acc_fc)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap='viridis')\n","plt.title('Confusion Matrix')\n","plt.show()"],"metadata":{"id":"ziv91MEPQgQl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXWJXLO5HJll"},"source":["### Train the CNN on the **shuffled data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n43wXtMuHJln"},"outputs":[],"source":["# check the shape of the shuffled data\n","# we need matrices as input\n","X_train_shuffle.shape,Y_train.shape,X_val_shuffle.shape,Y_val.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02CQCtVEP4oq"},"outputs":[],"source":["# compile model and intitialize weights\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SEQBad6jHJly"},"outputs":[],"source":["# train the model\n","history2=model2.fit(X_train_shuffle, Y_train,\n","                  batch_size=128,\n","                  epochs=10,\n","                  verbose=1,\n","                  validation_data=(X_val_shuffle, Y_val)\n","                 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_O6iw7xJHJmA"},"outputs":[],"source":["# plot the development of the accuracy and loss during training\n","plt.figure(figsize=(12,4))\n","plt.subplot(1,2,(1))\n","plt.plot(history2.history['accuracy'],linestyle='-.')\n","plt.plot(history2.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='lower right')\n","plt.subplot(1,2,(2))\n","plt.plot(history2.history['loss'],linestyle='-.')\n","plt.plot(history2.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'], loc='upper right')"]},{"cell_type":"markdown","source":["###"],"metadata":{"id":"UOr0t52wP32M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPT49d5THJmJ"},"outputs":[],"source":["#### Exercise\n","#### Use the trained model to calculate the accuracy and the confusion matrix on the test data\n","\n","### Your code here ###\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Wv898fZgjb-Z"},"source":["### ðŸ”§ **YOUR TASK:**\n","  #### Prediction on the test set after training on the shuffled data\n","- Use the CNN that was trained on the shuffled data to predict new unseen data (our testdata). We determine the confusion matrix and the accuracy on the testdata to evaluate the classification performance.\n","\n","#### Comparison\n","\n","- Compare the performances of the fcNN on the MNIST dataset to the CNN performances. What do you observe?  \n","- Compare the performance of the CNN on the original and on the shuffled dataset. Try to explain the differences.  \n"]},{"cell_type":"code","source":["### YOUR CODE HERE ###"],"metadata":{"id":"Ao78XboHQIxr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ðŸ”‘ **Solution:**\n"],"metadata":{"id":"0bDjRkCdQkCK"}},{"cell_type":"code","source":["# @title Solution Code { display-mode: \"form\" }\n","# predict each instance of the testset\n","pred=model2.predict(X_test_shuffle)\n","# get confusion matrix\n","cm = confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(pred, axis=1))\n","\n","acc_fc = np.sum(np.argmax(Y_test,axis=1)==np.argmax(pred,axis=1))/len(pred)\n","print(\"Accuracy = \" , acc_fc)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap='viridis')\n","plt.title('Confusion Matrix')\n","plt.show()"],"metadata":{"id":"Mix2M9mcQUEj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<details>\n","  <summary>ðŸ”‘ Click here to View Answers:</summary>\n","\n","\n","\n","----------\n","The MLP (MultiLayerPerceptron aka fully connected NN) from notebook 03 had a total number of trainable **parameters : 84060**, a NLL of ~ 0.1 and achieved an accuracy around 0.97\n","\n","The CNN used in this notebook only uses **35962 parameters**  which is less than **half the size** of the MLP and reaches ~ 0.98 accuracy and a loss of 0.05\n","\n","\n","\n","\n","----------\n","\n","\n","\n","\n","\n","\n","Surprisingly the accuracy on the testset is still ~ 0.95 when the dataset is shuffled! However its worse than using the real dataset ~ 0.98.\n","Somehow there are still structures in the reshuffled dataset which could be learned (since their all reshuffled in the same way) by a CNN.\n","\n","The overall structure and therefore local dependencies in the image get destroyed by the shuffling. Opposed to the FC NN, the performance of the CNN suffers if the images are shuffled. This makes sense since a CNN assumes by architecture that the ordering and local neighborhoods of the pixels matter (that is called a \"model bias\"): each neuron gets as input only a patch of neighboring pixels in the previous layer as input. The far-reaching correlations are learned by stacking more layers and hence increasing the perception field. Since a CNN has the \"model bias\" that neighborhood is essential, it does not have to learn that from scratch as a FC NN. Therefore, the CNN outperforms the FC NN when used on original MNIST image data but has roughly the same performance as a FC NN when provided with shuffled image data.\n","\n","</details>"],"metadata":{"id":"4pd2Y44_PAFz"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["0bDjRkCdQkCK"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}