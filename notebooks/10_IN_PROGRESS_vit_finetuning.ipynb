{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Vision Transformer (ViT) Finetuning\n",
    "In this notebook you will finetune a pretrained Vision Transformer to predict a class\n",
    "We won't train a model by ourself but rather use the power of freely available models which are pretrained by others on a large set of images (Imagenet\n",
    " 14'197'122 images 1000 Classes). \n",
    "\n",
    " There is  a library which provides us with the necessary models\n",
    " py**T**orch **IM**age **M**odels (timm):\n",
    " \n",
    "https://github.com/huggingface/pytorch-image-models\n",
    "https://huggingface.co/docs/hub/timm\n",
    " \n",
    " This notebook consist of the following steps:\n",
    "\n",
    "\n",
    "1.   Download & set the weights to a given modelarchitecture\n",
    "2.   Finetuen model on CIFAR10\n",
    "\n",
    "Imagenet: https://www.image-net.org/about.php\n",
    "\n",
    "VisionTransformer: https://arxiv.org/abs/2010.11929\n",
    "\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from timm import create_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model Loaded with Configuration: {'url': '', 'hf_hub_id': 'timm/vit_base_patch16_224.augreg2_in21k_ft_in1k', 'architecture': 'vit_base_patch16_224', 'tag': 'augreg2_in21k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'fixed_input_size': True, 'interpolation': 'bicubic', 'crop_pct': 0.9, 'crop_mode': 'center', 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5), 'num_classes': 1000, 'pool_size': None, 'first_conv': 'patch_embed.proj', 'classifier': 'head'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration\n",
    "model_name = \"vit_base_patch16_224\"\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize CIFAR-10 images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load Pretrained Model\n",
    "model = create_model(model_name, pretrained=True, num_classes=10)  # CIFAR-10 has 10 classes\n",
    "model = model.to(device)\n",
    "print(\"Model Loaded with Configuration:\", model.default_cfg)\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device,n_batches=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "\n",
    "        # Print a message after each batch\n",
    "        print(f\"Batch {batch_idx + 1}/{len(loader)} completed.\")\n",
    "        if n_batches == batch_idx:\n",
    "            break\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Train Loss: {running_loss/len(loader):.4f}, Accuracy: {acc:.2f}%\")\n",
    "    return running_loss / len(loader), acc\n",
    "\n",
    "# Testing Function\n",
    "def test(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            outputs_list.append(outputs)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            \n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Test Loss: {test_loss/len(loader):.4f}, Accuracy: {acc:.2f}%\")\n",
    "    return test_loss / len(loader), acc , outputs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets check the label distribution on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000.]),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true=list(test_dataset.targets)\n",
    "plt.title(\"True Test Label Distribution\")\n",
    "plt.hist(y_true,np.arange(0,11), edgecolor='black', align='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok lets now check what the model outputs when its not finetuned on the task\n",
    "- what do you expect? \n",
    "- note that the model has no notion of the cifar class assignemt.\n",
    "- also since the classification head is newly specified to 10 classes the weights are randomly initalized (for the mlp head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating the model before training:\")\n",
    "\n",
    "_, _ ,out= test(model, test_loader, criterion, device)\n",
    "output=[l.detach().cpu().numpy() for l in out]\n",
    "output=np.concatenate(output)\n",
    "plt.hist(list(np.argmax(output,axis=1)), edgecolor='black', align='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the accuracy / loss can  not be interpreted here since the classes can not be assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see what happens if we train with only with a few batches.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model Loaded with Configuration: {'url': '', 'hf_hub_id': 'timm/vit_base_patch16_224.augreg2_in21k_ft_in1k', 'architecture': 'vit_base_patch16_224', 'tag': 'augreg2_in21k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'fixed_input_size': True, 'interpolation': 'bicubic', 'crop_pct': 0.9, 'crop_mode': 'center', 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5), 'num_classes': 1000, 'pool_size': None, 'first_conv': 'patch_embed.proj', 'classifier': 'head'}\n",
      "Epoch 1/1\n",
      "Batch 1/391 completed.\n",
      "Batch 2/391 completed.\n",
      "Batch 3/391 completed.\n",
      "Batch 4/391 completed.\n",
      "Batch 5/391 completed.\n",
      "Batch 6/391 completed.\n",
      "Batch 7/391 completed.\n",
      "Batch 8/391 completed.\n",
      "Batch 9/391 completed.\n",
      "Batch 10/391 completed.\n",
      "Batch 11/391 completed.\n",
      "Batch 12/391 completed.\n",
      "Batch 13/391 completed.\n",
      "Batch 14/391 completed.\n",
      "Batch 15/391 completed.\n",
      "Batch 16/391 completed.\n",
      "Batch 17/391 completed.\n",
      "Batch 18/391 completed.\n",
      "Batch 19/391 completed.\n",
      "Batch 20/391 completed.\n",
      "Batch 21/391 completed.\n",
      "Batch 22/391 completed.\n",
      "Batch 23/391 completed.\n",
      "Batch 24/391 completed.\n",
      "Batch 25/391 completed.\n",
      "Batch 26/391 completed.\n",
      "Batch 27/391 completed.\n",
      "Batch 28/391 completed.\n",
      "Batch 29/391 completed.\n",
      "Batch 30/391 completed.\n",
      "Batch 31/391 completed.\n",
      "Batch 32/391 completed.\n",
      "Batch 33/391 completed.\n",
      "Batch 34/391 completed.\n",
      "Batch 35/391 completed.\n",
      "Batch 36/391 completed.\n",
      "Batch 37/391 completed.\n",
      "Batch 38/391 completed.\n",
      "Batch 39/391 completed.\n",
      "Batch 40/391 completed.\n",
      "Batch 41/391 completed.\n",
      "Batch 42/391 completed.\n",
      "Batch 43/391 completed.\n",
      "Batch 44/391 completed.\n",
      "Batch 45/391 completed.\n",
      "Batch 46/391 completed.\n",
      "Batch 47/391 completed.\n",
      "Batch 48/391 completed.\n",
      "Batch 49/391 completed.\n",
      "Batch 50/391 completed.\n",
      "Batch 51/391 completed.\n",
      "Batch 52/391 completed.\n",
      "Batch 53/391 completed.\n",
      "Batch 54/391 completed.\n",
      "Batch 55/391 completed.\n",
      "Batch 56/391 completed.\n",
      "Batch 57/391 completed.\n",
      "Batch 58/391 completed.\n",
      "Batch 59/391 completed.\n",
      "Batch 60/391 completed.\n",
      "Batch 61/391 completed.\n",
      "Batch 62/391 completed.\n",
      "Batch 63/391 completed.\n",
      "Batch 64/391 completed.\n",
      "Batch 65/391 completed.\n",
      "Batch 66/391 completed.\n",
      "Batch 67/391 completed.\n",
      "Batch 68/391 completed.\n",
      "Batch 69/391 completed.\n",
      "Batch 70/391 completed.\n",
      "Batch 71/391 completed.\n",
      "Batch 72/391 completed.\n",
      "Batch 73/391 completed.\n",
      "Batch 74/391 completed.\n",
      "Batch 75/391 completed.\n",
      "Batch 76/391 completed.\n",
      "Batch 77/391 completed.\n",
      "Batch 78/391 completed.\n",
      "Batch 79/391 completed.\n",
      "Batch 80/391 completed.\n",
      "Batch 81/391 completed.\n",
      "Batch 82/391 completed.\n",
      "Batch 83/391 completed.\n",
      "Batch 84/391 completed.\n",
      "Batch 85/391 completed.\n",
      "Batch 86/391 completed.\n",
      "Batch 87/391 completed.\n",
      "Batch 88/391 completed.\n",
      "Batch 89/391 completed.\n",
      "Batch 90/391 completed.\n",
      "Batch 91/391 completed.\n",
      "Batch 92/391 completed.\n",
      "Batch 93/391 completed.\n",
      "Batch 94/391 completed.\n",
      "Batch 95/391 completed.\n",
      "Batch 96/391 completed.\n",
      "Batch 97/391 completed.\n",
      "Batch 98/391 completed.\n",
      "Batch 99/391 completed.\n",
      "Batch 100/391 completed.\n",
      "Batch 101/391 completed.\n",
      "Batch 102/391 completed.\n",
      "Batch 103/391 completed.\n",
      "Batch 104/391 completed.\n",
      "Batch 105/391 completed.\n",
      "Batch 106/391 completed.\n",
      "Batch 107/391 completed.\n",
      "Batch 108/391 completed.\n",
      "Batch 109/391 completed.\n",
      "Batch 110/391 completed.\n",
      "Batch 111/391 completed.\n",
      "Batch 112/391 completed.\n",
      "Batch 113/391 completed.\n",
      "Batch 114/391 completed.\n",
      "Batch 115/391 completed.\n",
      "Batch 116/391 completed.\n",
      "Batch 117/391 completed.\n",
      "Batch 118/391 completed.\n",
      "Batch 119/391 completed.\n",
      "Batch 120/391 completed.\n",
      "Batch 121/391 completed.\n",
      "Batch 122/391 completed.\n",
      "Batch 123/391 completed.\n",
      "Batch 124/391 completed.\n",
      "Batch 125/391 completed.\n",
      "Batch 126/391 completed.\n",
      "Batch 127/391 completed.\n",
      "Batch 128/391 completed.\n",
      "Batch 129/391 completed.\n",
      "Batch 130/391 completed.\n",
      "Batch 131/391 completed.\n",
      "Batch 132/391 completed.\n",
      "Batch 133/391 completed.\n",
      "Batch 134/391 completed.\n",
      "Batch 135/391 completed.\n",
      "Batch 136/391 completed.\n",
      "Batch 137/391 completed.\n",
      "Batch 138/391 completed.\n",
      "Batch 139/391 completed.\n",
      "Batch 140/391 completed.\n",
      "Batch 141/391 completed.\n",
      "Batch 142/391 completed.\n",
      "Batch 143/391 completed.\n",
      "Batch 144/391 completed.\n",
      "Batch 145/391 completed.\n",
      "Batch 146/391 completed.\n",
      "Batch 147/391 completed.\n",
      "Batch 148/391 completed.\n",
      "Batch 149/391 completed.\n",
      "Batch 150/391 completed.\n",
      "Batch 151/391 completed.\n",
      "Batch 152/391 completed.\n",
      "Batch 153/391 completed.\n",
      "Batch 154/391 completed.\n",
      "Batch 155/391 completed.\n",
      "Batch 156/391 completed.\n",
      "Batch 157/391 completed.\n",
      "Batch 158/391 completed.\n",
      "Batch 159/391 completed.\n",
      "Batch 160/391 completed.\n",
      "Batch 161/391 completed.\n",
      "Batch 162/391 completed.\n",
      "Batch 163/391 completed.\n",
      "Batch 164/391 completed.\n",
      "Batch 165/391 completed.\n",
      "Batch 166/391 completed.\n",
      "Batch 167/391 completed.\n",
      "Batch 168/391 completed.\n",
      "Batch 169/391 completed.\n",
      "Batch 170/391 completed.\n",
      "Batch 171/391 completed.\n",
      "Batch 172/391 completed.\n",
      "Batch 173/391 completed.\n",
      "Batch 174/391 completed.\n",
      "Batch 175/391 completed.\n",
      "Batch 176/391 completed.\n",
      "Batch 177/391 completed.\n",
      "Batch 178/391 completed.\n",
      "Batch 179/391 completed.\n",
      "Batch 180/391 completed.\n",
      "Batch 181/391 completed.\n",
      "Batch 182/391 completed.\n",
      "Batch 183/391 completed.\n",
      "Batch 184/391 completed.\n",
      "Batch 185/391 completed.\n",
      "Batch 186/391 completed.\n",
      "Batch 187/391 completed.\n",
      "Batch 188/391 completed.\n",
      "Batch 189/391 completed.\n",
      "Batch 190/391 completed.\n",
      "Batch 191/391 completed.\n",
      "Batch 192/391 completed.\n",
      "Batch 193/391 completed.\n",
      "Batch 194/391 completed.\n",
      "Batch 195/391 completed.\n",
      "Batch 196/391 completed.\n",
      "Batch 197/391 completed.\n",
      "Batch 198/391 completed.\n",
      "Batch 199/391 completed.\n",
      "Batch 200/391 completed.\n",
      "Batch 201/391 completed.\n",
      "Batch 202/391 completed.\n",
      "Batch 203/391 completed.\n",
      "Batch 204/391 completed.\n",
      "Batch 205/391 completed.\n",
      "Batch 206/391 completed.\n",
      "Batch 207/391 completed.\n",
      "Batch 208/391 completed.\n",
      "Batch 209/391 completed.\n",
      "Batch 210/391 completed.\n",
      "Batch 211/391 completed.\n",
      "Batch 212/391 completed.\n",
      "Batch 213/391 completed.\n",
      "Batch 214/391 completed.\n",
      "Batch 215/391 completed.\n",
      "Batch 216/391 completed.\n",
      "Batch 217/391 completed.\n",
      "Batch 218/391 completed.\n",
      "Batch 219/391 completed.\n",
      "Batch 220/391 completed.\n",
      "Batch 221/391 completed.\n",
      "Batch 222/391 completed.\n",
      "Batch 223/391 completed.\n",
      "Batch 224/391 completed.\n",
      "Batch 225/391 completed.\n",
      "Batch 226/391 completed.\n",
      "Batch 227/391 completed.\n",
      "Batch 228/391 completed.\n",
      "Batch 229/391 completed.\n",
      "Batch 230/391 completed.\n",
      "Batch 231/391 completed.\n",
      "Batch 232/391 completed.\n",
      "Batch 233/391 completed.\n",
      "Batch 234/391 completed.\n",
      "Batch 235/391 completed.\n",
      "Batch 236/391 completed.\n",
      "Batch 237/391 completed.\n",
      "Batch 238/391 completed.\n",
      "Batch 239/391 completed.\n",
      "Batch 240/391 completed.\n",
      "Batch 241/391 completed.\n",
      "Batch 242/391 completed.\n",
      "Batch 243/391 completed.\n",
      "Batch 244/391 completed.\n",
      "Batch 245/391 completed.\n",
      "Batch 246/391 completed.\n",
      "Batch 247/391 completed.\n",
      "Batch 248/391 completed.\n",
      "Batch 249/391 completed.\n",
      "Batch 250/391 completed.\n",
      "Batch 251/391 completed.\n",
      "Batch 252/391 completed.\n",
      "Batch 253/391 completed.\n",
      "Batch 254/391 completed.\n",
      "Batch 255/391 completed.\n",
      "Batch 256/391 completed.\n",
      "Batch 257/391 completed.\n",
      "Batch 258/391 completed.\n",
      "Batch 259/391 completed.\n",
      "Batch 260/391 completed.\n",
      "Batch 261/391 completed.\n",
      "Batch 262/391 completed.\n",
      "Batch 263/391 completed.\n",
      "Batch 264/391 completed.\n",
      "Batch 265/391 completed.\n",
      "Batch 266/391 completed.\n",
      "Batch 267/391 completed.\n",
      "Batch 268/391 completed.\n",
      "Batch 269/391 completed.\n",
      "Batch 270/391 completed.\n",
      "Batch 271/391 completed.\n",
      "Batch 272/391 completed.\n",
      "Batch 273/391 completed.\n",
      "Batch 274/391 completed.\n",
      "Batch 275/391 completed.\n",
      "Batch 276/391 completed.\n",
      "Batch 277/391 completed.\n",
      "Batch 278/391 completed.\n",
      "Batch 279/391 completed.\n",
      "Batch 280/391 completed.\n",
      "Batch 281/391 completed.\n",
      "Batch 282/391 completed.\n",
      "Batch 283/391 completed.\n",
      "Batch 284/391 completed.\n",
      "Batch 285/391 completed.\n",
      "Batch 286/391 completed.\n",
      "Batch 287/391 completed.\n",
      "Batch 288/391 completed.\n",
      "Batch 289/391 completed.\n",
      "Batch 290/391 completed.\n",
      "Batch 291/391 completed.\n",
      "Batch 292/391 completed.\n",
      "Batch 293/391 completed.\n",
      "Batch 294/391 completed.\n",
      "Batch 295/391 completed.\n",
      "Batch 296/391 completed.\n",
      "Batch 297/391 completed.\n",
      "Batch 298/391 completed.\n",
      "Batch 299/391 completed.\n",
      "Batch 300/391 completed.\n",
      "Batch 301/391 completed.\n",
      "Batch 302/391 completed.\n",
      "Batch 303/391 completed.\n",
      "Batch 304/391 completed.\n",
      "Batch 305/391 completed.\n",
      "Batch 306/391 completed.\n",
      "Batch 307/391 completed.\n",
      "Batch 308/391 completed.\n",
      "Batch 309/391 completed.\n",
      "Batch 310/391 completed.\n",
      "Batch 311/391 completed.\n",
      "Batch 312/391 completed.\n",
      "Batch 313/391 completed.\n",
      "Batch 314/391 completed.\n",
      "Batch 315/391 completed.\n",
      "Batch 316/391 completed.\n",
      "Batch 317/391 completed.\n",
      "Batch 318/391 completed.\n",
      "Batch 319/391 completed.\n",
      "Batch 320/391 completed.\n",
      "Batch 321/391 completed.\n",
      "Batch 322/391 completed.\n",
      "Batch 323/391 completed.\n",
      "Batch 324/391 completed.\n",
      "Batch 325/391 completed.\n",
      "Batch 326/391 completed.\n",
      "Batch 327/391 completed.\n",
      "Batch 328/391 completed.\n",
      "Batch 329/391 completed.\n",
      "Batch 330/391 completed.\n",
      "Batch 331/391 completed.\n",
      "Batch 332/391 completed.\n",
      "Batch 333/391 completed.\n",
      "Batch 334/391 completed.\n",
      "Batch 335/391 completed.\n",
      "Batch 336/391 completed.\n",
      "Batch 337/391 completed.\n",
      "Batch 338/391 completed.\n",
      "Batch 339/391 completed.\n",
      "Batch 340/391 completed.\n",
      "Batch 341/391 completed.\n",
      "Batch 342/391 completed.\n",
      "Batch 343/391 completed.\n",
      "Batch 344/391 completed.\n",
      "Batch 345/391 completed.\n",
      "Batch 346/391 completed.\n",
      "Batch 347/391 completed.\n",
      "Batch 348/391 completed.\n",
      "Batch 349/391 completed.\n",
      "Batch 350/391 completed.\n",
      "Batch 351/391 completed.\n",
      "Batch 352/391 completed.\n",
      "Batch 353/391 completed.\n",
      "Batch 354/391 completed.\n",
      "Batch 355/391 completed.\n",
      "Batch 356/391 completed.\n",
      "Batch 357/391 completed.\n",
      "Batch 358/391 completed.\n",
      "Batch 359/391 completed.\n",
      "Batch 360/391 completed.\n",
      "Batch 361/391 completed.\n",
      "Batch 362/391 completed.\n",
      "Batch 363/391 completed.\n",
      "Batch 364/391 completed.\n",
      "Batch 365/391 completed.\n",
      "Batch 366/391 completed.\n",
      "Batch 367/391 completed.\n",
      "Batch 368/391 completed.\n",
      "Batch 369/391 completed.\n",
      "Batch 370/391 completed.\n",
      "Batch 371/391 completed.\n",
      "Batch 372/391 completed.\n",
      "Batch 373/391 completed.\n",
      "Batch 374/391 completed.\n",
      "Batch 375/391 completed.\n",
      "Batch 376/391 completed.\n",
      "Batch 377/391 completed.\n",
      "Batch 378/391 completed.\n",
      "Batch 379/391 completed.\n",
      "Batch 380/391 completed.\n",
      "Batch 381/391 completed.\n",
      "Batch 382/391 completed.\n",
      "Batch 383/391 completed.\n",
      "Batch 384/391 completed.\n",
      "Batch 385/391 completed.\n",
      "Batch 386/391 completed.\n",
      "Batch 387/391 completed.\n",
      "Batch 388/391 completed.\n",
      "Batch 389/391 completed.\n",
      "Batch 390/391 completed.\n",
      "Batch 391/391 completed.\n",
      "Train Loss: 0.1488, Accuracy: 95.15%\n",
      "Test Loss: 0.1191, Accuracy: 96.01%\n",
      "Fine-tuning completed!\n"
     ]
    }
   ],
   "source": [
    "n_batches=10\n",
    "\n",
    "# Configuration\n",
    "model_name = \"vit_base_patch16_224\"\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "learning_rate = 1e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# Load Pretrained Model\n",
    "model = create_model(model_name, pretrained=True, num_classes=10)  # surprise surprise CIFAR-10 has 10 classes\n",
    "model = model.to(device)\n",
    "print(\"Model Loaded with Configuration:\", model.default_cfg)\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device,n_batches=n_batches-1)\n",
    "    test_loss, test_acc,_ = test(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Fine-tuning with {n_batches} batches completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- just seeing 10* 640 images (with random rotations)  once was enough to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want you can finetune the model furteher\n",
    "- adjust epochs\n",
    "- track loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_name = \"vit_base_patch16_224\"\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# Load Pretrained Model\n",
    "model = create_model(model_name, pretrained=True, num_classes=10)  # surprise surprise CIFAR-10 has 10 classes\n",
    "model = model.to(device)\n",
    "print(\"Model Loaded with Configuration:\", model.default_cfg)\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device,n_batches=None)\n",
    "    test_loss, test_acc,_ = test(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"Fine-tuning completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
